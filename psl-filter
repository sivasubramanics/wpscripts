#!/usr/bin/env python3
# script to filter the psl file (from blat output) to remove the alignments with low identity and coverage
# usage: python filter_psl.py -i <input_psl> -o <output_psl> -q <query_coverage_threshold> -d <identity_threshold> -b <max_blocks_threshold>
# contact: siva.selvanayagam[at]wur.nl
# data: 06-12-2023

import argparse
import sys
from collections import defaultdict

HEAD_SUMMARY = "qname\tqlen\ttname\ttstart\ttend\tstrand\tq_aln_len\tt_aln_len\tqcov\ttcov\tidentity\tblockcount\tpslscore\tqscore"
HEAD_LOCI = "qname\tnum_hits\tloci"
HEAD_HITS = "qname\tnum_hits\tref_id"


class PSL:
    def __init__(self, line):
        self.line = line.strip().split('\t')
        self.matches = int(self.line[0])
        self.mismatches = int(self.line[1])
        self.rep_matches = int(self.line[2])
        self.n_count = int(self.line[3])
        self.q_num_insert = int(self.line[4])
        self.q_base_insert = int(self.line[5])
        self.t_num_insert = int(self.line[6])
        self.t_base_insert = int(self.line[7])
        self.strand = self.line[8]
        self.q_name = self.line[9]
        self.q_size = int(self.line[10])
        self.q_start = int(self.line[11])
        self.q_end = int(self.line[12])
        self.t_name = self.line[13]
        self.t_size = int(self.line[14])
        self.t_start = int(self.line[15])
        self.t_end = int(self.line[16])
        self.block_count = int(self.line[17])
        self.block_sizes = [int(x) for x in self.line[18].split(',') if x]
        self.q_starts = [int(x) for x in self.line[19].split(',') if x]
        self.t_starts = [int(x) for x in self.line[20].split(',') if x]
        self.psl_score = self.matches + (self.rep_matches / 2) - self.mismatches - self.q_num_insert - self.t_num_insert
        self.q_score = self.psl_score / self.q_size * 1000

    def get_query_coverage(self):
        return (self.matches + self.mismatches + self.rep_matches) / self.q_size

    def get_target_coverage(self):
        return (self.matches + self.mismatches + self.rep_matches) / self.t_size

    def get_identity(self):
        return (self.matches + self.rep_matches) / (self.matches + self.mismatches + self.rep_matches)

    def get_max_blocks(self):
        return max(self.block_sizes)

    def __str__(self):
        return '\t'.join(self.line)

    def get_blocks_count(self):
        return self.block_count

    def to_summary(self):
        # return qname, qlen, tname, tstart, tend, strand, q_aln_len, t_aln_len, qcov, identity, blockcount, pslscore
        return f"{self.q_name}\t{self.q_size}\t{self.t_name}\t{self.t_start}\t{self.t_end}\t{self.strand}\t{self.q_end - self.q_start}\t{self.t_end - self.t_start}\t{self.get_query_coverage() * 100:.2f}\t{self.get_target_coverage() * 100:.2f}\t{self.get_identity() * 100:.2f}\t{self.block_count}\t{self.psl_score:.0f}\t{self.q_score:.0f}"

    def to_gtf(self):
        gtf_lines = []
        # transcript line
        gtf_lines.append(
            f"{self.t_name}\tblat\ttranscript\t{self.t_start + 1}\t{self.t_end}\t{self.q_score:.0f}\t{self.strand}\t.\tgene_id \"{self.q_name}\"; transcript_id \"{self.q_name}\";")
        for i in range(self.block_count):
            # exon lines
            gtf_lines.append(
                f"{self.t_name}\tblat\texon\t{self.t_starts[i] + 1}\t{self.t_starts[i] + self.block_sizes[i]}\t.\t{self.strand}\t.\tgene_id \"{self.q_name}\"; transcript_id \"{self.q_name}\";")

        return '\n'.join(gtf_lines)

    def to_bed(self):
        if self.strand == "+":
            rgb = "255,0,0"
        else:
            rgb = "0,0,255"
        return f"{self.t_name}\t{self.t_start}\t{self.t_end}\t{self.q_name}\t{self.q_score:.0f}\t{self.strand}\t{self.t_start}\t{self.t_end}\t{rgb}\t{self.block_count}\t{','.join([str(x) for x in self.block_sizes])}\t{','.join([str(x) for x in self.t_starts])}"


def parse_fasta(fasta_file):
    fasta_dict = defaultdict(str)
    with open(fasta_file, 'r') as f:
        name = ""
        sequence = ""
        begun = False
        for line in f:
            if line.startswith(">"):
                if begun:
                    fasta_dict[name] = len(sequence)
                    sequence = ""
                name = line.strip().split(" ")[0].lstrip(">")
                begun = True
            else:
                sequence += line.strip()
        fasta_dict[name] = len(sequence)
    return fasta_dict


def parse_psl(input):
    """
    Parse the PSL file and return the list of PSL object per query
    """
    psls = []
    last_q_name = ""
    with open(input, 'r') as f:
        for line in f:
            psl = PSL(line)
            if psl.q_name != last_q_name and last_q_name:
                yield psls
                psls = []
            psls.append(psl)
            last_q_name = psl.q_name
        yield psls


def genome_psl(input, out, qscore_cutoff=0.0):
    """
    Parse the PSL file, get the best hit for each query and write coverage summary in output file
    """
    out_psl = open(f"{out}.psl", 'w')
    out_gtf = open(f"{out}.gtf", 'w')
    out_bed = open(f"{out}.bed", 'w')
    out_loci = open(f"{out}.loci", 'w')
    out_loci.write(f"{HEAD_LOCI}\n")
    out_summary = open(f"{out}.summary", 'w')
    out_summary.write(f"{HEAD_SUMMARY}\n")

    best_hits = []
    for psls in parse_psl(input):
        best_hits = best_hit_psl(psls)
        loci = ""
        q_name = best_hits[0].q_name
        n_hits = 0
        for i in range(len(best_hits)):
            psl = best_hits[i]
            if psl.q_score < qscore_cutoff:
                continue
            loci += f"{psl.t_name}:{psl.t_start}-{psl.t_end}:{psl.strand};"
            n_hits += 1
            out_psl.write(f"{psl}\n")
            out_summary.write(f"{psl.to_summary()}\n")
            if i > 0:
                # since GTF can not have same transcript id, we append _i to the transcript id
                psl.q_name = f"{psl.q_name}_{i}"
            out_gtf.write(f"{psl.to_gtf()}\n")
            out_bed.write(f"{psl.to_bed()}\n")
        if loci:
            out_loci.write(f"{q_name}\t{n_hits}\t{loci}\n")


def best_hit_psl(psls):
    """
    Get the best hit from the list of PSL objects
    """
    best_psl = []
    for psl in psls:
        if best_psl == []:
            best_psl = [psl]
        else:
            # check if the current psl has better score than the last element of best psl
            if psl.psl_score > best_psl[-1].psl_score:
                best_psl = [psl]
            elif psl.psl_score == best_psl[-1].psl_score:
                best_psl.append(psl)
    return best_psl


def protein_psl(input, out, cutoff_score=0.0):
    """
    Parse the PSL file, get the best hit for each query and write coverage summary in output file
    """
    out_psl = open(f"{out}.psl", 'w')
    out_hits = open(f"{out}.hits", 'w')
    out_hits.write(f"{HEAD_HITS}\n")
    out_summary = open(f"{out}.summary", 'w')
    out_summary.write(f"{HEAD_SUMMARY}\n")

    best_hits = []
    for psls in parse_psl(input):
        best_hits = best_hit_psl(psls)
        loci = ""
        q_name = best_hits[0].q_name
        n_hits = 0
        for i in range(len(best_hits)):
            psl = best_hits[i]
            if psl.q_score < cutoff_score:
                continue
            loci += f"{psl.t_name};"
            n_hits += 1
            out_psl.write(f"{psl}\n")
            out_summary.write(f"{psl.to_summary()}\n")
        if loci:
            out_hits.write(f"{q_name}\t{n_hits}\t{loci}\n")



def main():
    # create argument parser with subcommands filter, compare
    parser = argparse.ArgumentParser(description='script to process PSL files')
    subparsers = parser.add_subparsers(help='sub-command help', dest='command')
    filter_parser = subparsers.add_parser('filter', help='filter psl file', description='filter psl file')
    filter_parser.add_argument('-i', '--input', help='input psl file', required=True)
    filter_parser.add_argument('-o', '--output', help='output psl file', required=True)
    filter_parser.add_argument('-q', '--query_coverage', help='query coverage threshold', required=False, type=float,
                               default=0.4)
    filter_parser.add_argument('-t', '--target_coverage', help='target coverage threshold', required=False, type=float,
                               default=0.4)
    filter_parser.add_argument('-d', '--identity', help='identity threshold', required=False, type=float, default=0.9)
    filter_parser.add_argument('-b', '--max_blocks', help='max blocks threshold', required=False, type=int, default=100)
    filter_parser.add_argument('-x', '--query_fasta', help='query fasta file', required=False)
    filter_parser.add_argument('-y', '--target_fasta', help='target fasta file', required=False)

    best_hit_parser = subparsers.add_parser('best_hit', help='retain only the best hit from the PSL file',
                                            description='retain only the best hit from the PSL file')
    best_hit_parser.add_argument('-i', '--input', help='input psl file', required=True)
    best_hit_parser.add_argument('-o', '--output', help='output psl file', required=True)

    sort_psl_parser = subparsers.add_parser('sort', help='sort the psl file', description='sort the psl file')
    sort_psl_parser.add_argument('-i', '--input', help='input psl file', required=True)
    sort_psl_parser.add_argument('-o', '--output', help='output psl file', required=True)

    genome_psl_parser = subparsers.add_parser('genome_psl', help='parse the PSL file, rna mapped on genome',
                                              description='parse the PSL file, rna mapped on genome')
    genome_psl_parser.add_argument('-i', '--input', help='input psl file', required=True)
    genome_psl_parser.add_argument('-o', '--out', help='output prefix', required=True)
    genome_psl_parser.add_argument('-s', '--cutoff_score', help='cutoff score (0-999)', required=False, type=float,
                                   default=0.0)

    protein_psl_parser = subparsers.add_parser('protein_psl', help='parse the PSL file, protein mapped on proteins',
                                                description='parse the PSL file, protein mapped on proteins')
    protein_psl_parser.add_argument('-i', '--input', help='input psl file', required=True)
    protein_psl_parser.add_argument('-o', '--out', help='output prefix', required=True)
    protein_psl_parser.add_argument('-s', '--cutoff_score', help='cutoff score (0-999)', required=False, type=float,
                                    default=0.0)

    args = parser.parse_args(args=None if sys.argv[1:] else ['--help'])

    if args.command == 'filter':
        query_fasta = None
        target_fasta = None
        if args.query_fasta:
            query_fasta = parse_fasta(args.query_fasta)
        if args.target_fasta:
            target_fasta = parse_fasta(args.target_fasta)
        filter_psl(args.input, args.output, args.query_coverage, args.identity, args.max_blocks, query_fasta,
                   target_fasta)

    if args.command == 'best_hit':
        best_hit(args.input, args.output)

    if args.command == 'sort':
        sort_psl(args.input, args.output)

    if args.command == 'genome_psl':
        genome_psl(args.input, args.out, args.cutoff_score)

    if args.command == 'protein_psl':
        protein_psl(args.input, args.out, args.cutoff_score)


def filter_psl(in_file, out_file, query_coverage, identity, max_blocks, query_fasta=None, target_fasta=None):
    with open(in_file, 'r') as f, open(out_file, 'w') as g:
        for line in f:
            psl = PSL(line)
            if psl.get_query_coverage() < query_coverage or psl.get_identity() < identity or psl.get_blocks_count() > max_blocks:
                continue
            if query_fasta:
                if psl.q_name not in query_fasta:
                    continue
            if target_fasta:
                if psl.t_name not in target_fasta:
                    continue
            g.write(str(psl) + '\n')


def best_hit(in_file, out_file):
    prev_q_name = ""
    psls = []
    scores = []
    with open(in_file, 'r') as f, open(out_file, 'w') as g, open(f"{out_file}.scores", 'w') as h:
        for line in f:
            psl = PSL(line)
            if psl.q_name == psl.t_name:
                continue
            h.write(f"{str(psl)}\t{psl.psl_score}\n")
            if prev_q_name == psl.q_name:
                psls.append(psl)
                scores.append(psl.psl_score)
            else:
                if psls:
                    max_score = max(scores)
                    if scores.count(max_score) > 1:
                        for i in range(len(scores)):
                            if scores[i] == max_score:
                                g.write(str(psls[i]) + '\n')
                    else:
                        g.write(str(psls[scores.index(max_score)]) + '\n')
                psls = [psl]
                scores = [psl.psl_score]
            prev_q_name = psl.q_name


def sort_psl(input, output):
    prev_q_name = ""
    psls = []
    scores = []
    with open(input, 'r') as f, open(output, 'w') as g:
        for line in f:
            psl = PSL(line)
            if prev_q_name == psl.q_name:
                psls.append(psl)
                scores.append(psl.psl_score)
            else:
                if psls:
                    psls = sort_lists(psls, scores)
                    for p in psls:
                        g.write(f"{str(p)}\t{p.psl_score}\n")
                psls = [psl]
                scores = [psl.psl_score]
            prev_q_name = psl.q_name


def sort_lists(list_a, list_b):
    # Combine the two lists into tuples
    combined = zip(list_a, list_b)

    # Reverse Sort the combined list based on the scores (second element of each tuple)
    sorted_combined = sorted(combined, key=lambda x: x[1], reverse=True)

    # Extract the rearranged list_a
    rearranged_list_a = [item[0] for item in sorted_combined]
    return rearranged_list_a


if __name__ == "__main__":
    main()
